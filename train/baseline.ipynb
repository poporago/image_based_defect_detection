{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgPkNRHcjbgx"
   },
   "source": [
    "# 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDr7vQWDkAzU"
   },
   "outputs": [],
   "source": [
    "#! pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s7yWsjIvjbg1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjBRWpIDjbg2"
   },
   "source": [
    "# Configuration 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Wj0FhCWEfcZ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7WZ5j0-FB0A"
   },
   "outputs": [],
   "source": [
    "! unzip /content/drive/MyDrive/yeardream_2nd/train.zip -d /content/drive/MyDrive/yeardream_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-aFgfo90F6Hj"
   },
   "outputs": [],
   "source": [
    "! unzip /content/drive/MyDrive/yeardream_2nd/test.zip -d /content/drive/MyDrive/yeardream_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1LLAAMdjbg2"
   },
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "cfg = dotdict(\n",
    "    device='cuda',#'cuda' #cpu\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    lr=1e-4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBrHmd5jjbg3"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 경로 설정\n",
    "data_dir = '/content/drive/MyDrive/yeardream_2nd'\n",
    "train_dir = data_dir + '/train'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzuzbADpjbg3"
   },
   "source": [
    "# Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjXjcmC9jbg3"
   },
   "outputs": [],
   "source": [
    "# 데이터 수량 체크\n",
    "train_defect_images = glob(train_dir + '/defect_images/*.png')\n",
    "train_normal_images = glob(train_dir + '/normal_images/*.png')\n",
    "\n",
    "print(f'total number of train dataset : {len(train_defect_images) + len(train_normal_images)}, defect : {len(train_defect_images)}, normal : {len(train_normal_images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P20gUVufjbg4"
   },
   "outputs": [],
   "source": [
    "# 클래스 분포 체크\n",
    "plt.bar(['defect', 'normal'], [len(train_defect_images), len(train_normal_images)], color=['red', 'blue'])\n",
    "plt.title('dist. of train dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3cXN36njbg5"
   },
   "source": [
    "# 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgpyH5-xjbg5"
   },
   "outputs": [],
   "source": [
    "total_dataset = train_defect_images + train_normal_images\n",
    "label = [1] * len(train_defect_images) + [0] * len(train_normal_images)\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_defect_images+train_normal_images, label, test_size=0.3, random_state=2025, stratify=label)\n",
    "\n",
    "print(f'train dataset : {len(X_train)}, val dataset : {len(X_val)}')\n",
    "print(f'train label : {len(y_train)}, val label : {len(y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzEpKZs-jbg5"
   },
   "source": [
    "# Pytorch CustomDataset 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpNs4vldjbg6"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = image / 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f214yCwsjbg6"
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "test_dataset = CustomDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIyqmAkajbg6"
   },
   "outputs": [],
   "source": [
    "# 데이터 샘플 체크\n",
    "for batch in train_loader:\n",
    "    imgs, labels = batch\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False) # 총 사진의 개수만큼 plot\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        axs[0, i].imshow(img.squeeze(), cmap='gray')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxrkBxcKjbg6"
   },
   "source": [
    "# CNN Model 정의 (resnet18d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n11xGdd5jbg6"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.encoder =  timm.create_model('resnet18d', pretrained=True, in_chans=1)\n",
    "        # self.encoder =  timm.create_model('resnet34d', pretrained=True, in_chans=1)\n",
    "\n",
    "        self.head = nn.Linear(1000, 1)\n",
    "\n",
    "    def forward(self, image, mode='train'):\n",
    "        x = self.encoder(image)\n",
    "        output = self.head(x)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFwo2jffjbg6"
   },
   "source": [
    "# 모델, Loss, Optimizer 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbuO_Z5bjbg6"
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "model = model.to(cfg.device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFKoQJX3jbg6"
   },
   "source": [
    "# 학습 모델 저장 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVSRhvmpjbg7"
   },
   "outputs": [],
   "source": [
    "model_dir = './models'\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBTrZR2Njbg7"
   },
   "source": [
    "# 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_h-kje5jbg7"
   },
   "outputs": [],
   "source": [
    "# Train and Valid Loop\n",
    "\n",
    "metric_best = 0.\n",
    "model_file = os.path.join(model_dir, f'best.pt')\n",
    "\n",
    "for epoch in range(cfg.epochs):\n",
    "    # Train Loop\n",
    "    train_loss = 0\n",
    "    train_outputs = []\n",
    "    train_labels = []\n",
    "    for batch in tqdm(train_loader, desc=f'train-{epoch}'):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        imgs = imgs.to(cfg.device).float()\n",
    "        labels = labels.to(cfg.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(imgs.unsqueeze(1))\n",
    "        loss = criterion(output, labels.unsqueeze(1).float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_outputs.append(output.cpu().detach())\n",
    "        train_labels.append(labels.cpu().detach())\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation Loop\n",
    "    val_loss = 0\n",
    "    val_outputs = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f'val-{epoch}'):\n",
    "            imgs, labels = batch\n",
    "\n",
    "            imgs = imgs.to(cfg.device).float()\n",
    "            labels = labels.to(cfg.device)\n",
    "\n",
    "            output = model(imgs.unsqueeze(1))\n",
    "            loss = criterion(output, labels.unsqueeze(1).float())\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_outputs.append(output.cpu().detach())\n",
    "            val_labels.append(labels.cpu().detach())\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    train_outputs = (torch.cat(train_outputs) > 0.5).float().squeeze(-1)\n",
    "    val_outputs = (torch.cat(val_outputs) > 0.5).float().squeeze(-1)\n",
    "    train_labels = torch.cat(train_labels)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "\n",
    "    train_acc = accuracy_score(train_labels, train_outputs)\n",
    "    val_acc = accuracy_score(val_labels, val_outputs)\n",
    "\n",
    "    train_f1 = f1_score(train_labels, train_outputs, average='macro')\n",
    "    val_f1 = f1_score(val_labels, val_outputs, average='macro')\n",
    "\n",
    "    if val_f1 > metric_best:\n",
    "        print(f'metric_best ({metric_best:.6f} --> {val_f1:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "        metric_best = val_f1\n",
    "\n",
    "    print(f'Epoch: {epoch}, Train Loss: {train_loss}, Val Loss: {val_loss}, Train Acc: {train_acc}, Val Acc: {val_acc}, Train F1: {train_f1}, Val F1: {val_f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtVaVvJLjbg7"
   },
   "source": [
    "# Pytorch CustomTestDataset 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izD2Uqcpjbg7"
   },
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_path = self.image_paths[idx]\n",
    "        image_name = os.path.basename(image_path)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = image / 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlJqjJX2jbg7"
   },
   "outputs": [],
   "source": [
    "test_images = glob(test_dir + '/images/*.png')\n",
    "\n",
    "print(f'the number of test images : {len(test_images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlwE7PDajbg7"
   },
   "outputs": [],
   "source": [
    "test_dataset = CustomTestDataset(test_images)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFrN37Dmjbg7"
   },
   "source": [
    "# 학습된 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKZkM1lvjbg7"
   },
   "outputs": [],
   "source": [
    "model_dir = './models'\n",
    "model_file = os.path.join(model_dir, f'best.pt')\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model = model.to(cfg.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tq6gjdetjbg7"
   },
   "source": [
    "# 추론 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvtpYdKwjbg8"
   },
   "outputs": [],
   "source": [
    "image_names = []\n",
    "test_outputs = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader)):\n",
    "        imgs, image_name = batch\n",
    "        imgs = imgs.to(cfg.device).float()\n",
    "\n",
    "        output = model(imgs.unsqueeze(1))\n",
    "        test_outputs.append(output.cpu().detach())\n",
    "        image_names.extend(image_name)\n",
    "\n",
    "test_outputs = (torch.cat(test_outputs) > 0.5).int().squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtUD4y80jbg8"
   },
   "source": [
    "# 추론 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECAiHHZ4jbg8"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': image_names, 'answer': test_outputs.tolist()})\n",
    "submission = submission.sort_values(by=['ImageId']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6cI7WqCjbg8"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVtXSdZLjbg8"
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Qz1xyBojbg8"
   },
   "outputs": [],
   "source": [
    "submission['answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Wlwira7O19v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
